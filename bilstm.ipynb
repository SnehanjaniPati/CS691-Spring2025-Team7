{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11439336,"sourceType":"datasetVersion","datasetId":7165760}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. CONFIG \nDefine paths, model filenames, and all hyper‑parameters in one place:\n- Data path, output weight file  \n- Embedding/LSTM dimensions, layers, bidirectionality, dropout  \n- Training settings (max length, batch size, epochs, learning rate)  \n- Vocabulary minimum frequency & random seed  \n","metadata":{}},{"cell_type":"code","source":"# 1. CONFIG\nDATA_PATH      = \"/kaggle/input/sentim/processed_sentiment_data.csv\"\nMODEL_WEIGHTS  = \"./bilstm_sentiment.pt\"\nEMBED_DIM      = 128\nHIDDEN_DIM     = 256\nN_LAYERS       = 2\nBIDIRECTIONAL  = True\nDROPOUT        = 0.3\nMAX_LEN        = 128\nBATCH_SIZE     = 64\nEPOCHS         = 6\nLR             = 3e-4\nMIN_FREQ       = 2\nSEED           = 42\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.024768Z","iopub.execute_input":"2025-04-17T04:07:02.025036Z","iopub.status.idle":"2025-04-17T04:07:02.030108Z","shell.execute_reply.started":"2025-04-17T04:07:02.025017Z","shell.execute_reply":"2025-04-17T04:07:02.029180Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# 2. IMPORTS & REPRODUCIBILITY\n- Standard libs (regex, random, time, warnings)  \n- NumPy, pandas for data handling  \n- PyTorch APIs for model, training, device  \n- sklearn metrics, DataLoader for batching  \n- Set global seeds and deterministic behavior  \n","metadata":{}},{"cell_type":"code","source":"# 2. IMPORTS & REPRODUCIBILITY\nimport re, random, time, collections, warnings, sys\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom torch.utils.data import Dataset, DataLoader\n\n# reproducibility\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntorch.backends.cudnn.deterministic = True\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.031334Z","iopub.execute_input":"2025-04-17T04:07:02.031587Z","iopub.status.idle":"2025-04-17T04:07:02.045711Z","shell.execute_reply.started":"2025-04-17T04:07:02.031569Z","shell.execute_reply":"2025-04-17T04:07:02.044885Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# 3. TOKENIZER & VOCAB\n- Simple regex‑based tokenizer  \n- `Vocab` class to build token ↔ index maps, keeping only words ≥ `MIN_FREQ`  \n- Special tokens `<pad>` and `<unk>`  \n","metadata":{}},{"cell_type":"code","source":"# 3. TOKENIZER & VOCAB\n_token_re = re.compile(r\"\\w+|[^\\w\\s]\", re.UNICODE)\n\ndef tokenize(text: str):\n    return _token_re.findall(text.lower())\n\nclass Vocab:\n    def __init__(self, counter, min_freq=1, specials=None):\n        specials = specials or []\n        # include specials first, then tokens ≥ min_freq\n        self.itos = specials + [\n            w for w, c in counter.items()\n            if c >= min_freq and w not in specials\n        ]\n        self.stoi = {w: i for i, w in enumerate(self.itos)}\n\n    def __len__(self):\n        return len(self.itos)\n\n    def __getitem__(self, token):\n        # return index or <unk>\n        return self.stoi.get(token, self.stoi[\"<unk>\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.046593Z","iopub.execute_input":"2025-04-17T04:07:02.047130Z","iopub.status.idle":"2025-04-17T04:07:02.058851Z","shell.execute_reply.started":"2025-04-17T04:07:02.047114Z","shell.execute_reply":"2025-04-17T04:07:02.058214Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# 4. DATASET\n- `SentimentDS` wraps a DataFrame of `text` & `sentiment`  \n- Builds its own vocab on `build_vocab=True`  \n- Encodes text → list of token‑IDs, truncated to `MAX_LEN`  \n- Maps sentiment strings → integer labels  \n","metadata":{}},{"cell_type":"code","source":"# 4. DATASET\nclass SentimentDS(Dataset):\n    def __init__(self, df, vocab=None, build_vocab=False):\n        self.texts = df[\"text\"].fillna(\"\").tolist()\n        self.orig_labels = df[\"sentiment\"].tolist()\n\n        # label mappings\n        self.label2id = {\n            l: i for i, l in enumerate(sorted(set(self.orig_labels)))\n        }\n        self.id2label = {i: l for l, i in self.label2id.items()}\n        self.labels = [self.label2id[l] for l in self.orig_labels]\n\n        # build or reuse vocab\n        if build_vocab:\n            counter = collections.Counter()\n            for t in self.texts:\n                counter.update(tokenize(t))\n            self.vocab = Vocab(counter, MIN_FREQ, specials=[\"<pad>\", \"<unk>\"])\n        else:\n            self.vocab = vocab\n\n    def encode(self, text):\n        ids = [self.vocab[t] for t in tokenize(text)[:MAX_LEN]]\n        if not ids:  # protect against blank text\n            ids = [self.vocab[\"<unk>\"]]\n        return ids\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        seq = torch.tensor(self.encode(self.texts[idx]), dtype=torch.long)\n        label = self.labels[idx]\n        return seq, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.059710Z","iopub.execute_input":"2025-04-17T04:07:02.059965Z","iopub.status.idle":"2025-04-17T04:07:02.071006Z","shell.execute_reply.started":"2025-04-17T04:07:02.059940Z","shell.execute_reply":"2025-04-17T04:07:02.070230Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# 5. DATA PREPARATION\n- Read full CSV, split into train/val (80/20)  \n- Build vocab on training set  \n- Create PyTorch `DataLoader` with padding collate fn  \n","metadata":{}},{"cell_type":"code","source":"# 5. DATA PREPARATION\ndf_all   = pd.read_csv(DATA_PATH)\ndf_train = df_all.sample(frac=0.8, random_state=SEED)\ndf_val   = df_all.drop(df_train.index)\n\n# datasets\ntrain_ds = SentimentDS(df_train, build_vocab=True)\nVOCAB    = train_ds.vocab\nval_ds   = SentimentDS(df_val, vocab=VOCAB)\n\nPAD_IDX   = VOCAB[\"<pad>\"]\nN_CLASSES = len(train_ds.label2id)\n\n# collate_fn for padding & lengths\ndef collate(batch):\n    seqs, labels = zip(*batch)\n    lengths = torch.tensor([len(s) for s in seqs], device=DEVICE)\n    padded  = nn.utils.rnn.pad_sequence(\n        seqs, batch_first=True, padding_value=PAD_IDX\n    )\n    return padded.to(DEVICE), lengths, torch.tensor(labels, device=DEVICE)\n\ntrain_loader = DataLoader(\n    train_ds, BATCH_SIZE, shuffle=True, collate_fn=collate\n)\nval_loader = DataLoader(\n    val_ds, BATCH_SIZE, shuffle=False, collate_fn=collate\n)\n\nprint(f\"Vocabulary size: {len(VOCAB)}    Classes: {N_CLASSES}\", file=sys.stderr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.072388Z","iopub.execute_input":"2025-04-17T04:07:02.072620Z","iopub.status.idle":"2025-04-17T04:07:02.201687Z","shell.execute_reply.started":"2025-04-17T04:07:02.072606Z","shell.execute_reply":"2025-04-17T04:07:02.200960Z"}},"outputs":[{"name":"stderr","text":"Vocabulary size: 4330    Classes: 3\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# 6. MODEL\n- `BiLSTMClassifier` with embedding, packed LSTM, dropout, and final linear layer  \n- Supports bidirectional LSTM and variable number of layers  \n","metadata":{}},{"cell_type":"code","source":"# 6. MODEL\nclass BiLSTMClassifier(nn.Module):\n    def __init__(\n        self, vocab_size, embed_dim, hidden_dim, n_layers,\n        n_classes, bidir=True, dropout=0.3, pad_idx=0\n    ):\n        super().__init__()\n        self.embedding = nn.Embedding(\n            vocab_size, embed_dim, padding_idx=pad_idx\n        )\n        self.lstm = nn.LSTM(\n            embed_dim, hidden_dim, n_layers,\n            batch_first=True, bidirectional=bidir,\n            dropout=dropout if n_layers > 1 else 0.0\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(\n            hidden_dim * (2 if bidir else 1), n_classes\n        )\n        self.bidir = bidir\n\n    def forward(self, x, lengths):\n        emb = self.dropout(self.embedding(x))\n        packed = nn.utils.rnn.pack_padded_sequence(\n            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        _, (h, _) = self.lstm(packed)\n        # concat last hidden states from both directions if bidir\n        if self.bidir:\n            h = torch.cat((h[-2], h[-1]), dim=1)\n        else:\n            h = h[-1]\n        return self.fc(self.dropout(h))\n\n# instantiate, loss & optimizer\nmodel = BiLSTMClassifier(\n    len(VOCAB), EMBED_DIM, HIDDEN_DIM,\n    N_LAYERS, N_CLASSES, BIDIRECTIONAL,\n    DROPOUT, PAD_IDX\n).to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.202470Z","iopub.execute_input":"2025-04-17T04:07:02.202713Z","iopub.status.idle":"2025-04-17T04:07:02.247320Z","shell.execute_reply.started":"2025-04-17T04:07:02.202687Z","shell.execute_reply":"2025-04-17T04:07:02.246778Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# 7. TRAIN / EVAL FUNCTIONS\n- `run_epoch` handles one pass (train or eval):  \n  - loops batches, computes loss  \n  - backprop + step if training  \n  - collects preds & ground truths  \n  - returns avg loss & accuracy  \n","metadata":{}},{"cell_type":"code","source":"# 7. TRAIN / EVAL FUNCTIONS\ndef run_epoch(loader, train=True):\n    if train:\n        model.train()\n    else:\n        model.eval()\n    total_loss, preds, gts = 0.0, [], []\n    for x, lengths, y in loader:\n        if train:\n            optimizer.zero_grad()\n        logits = model(x, lengths)\n        loss   = criterion(logits, y)\n        if train:\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * y.size(0)\n        preds.extend(logits.argmax(1).tolist())\n        gts.extend(y.tolist())\n    avg_loss = total_loss / len(loader.dataset)\n    acc = accuracy_score(gts, preds)\n    return avg_loss, acc, preds, gts\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.248743Z","iopub.execute_input":"2025-04-17T04:07:02.248958Z","iopub.status.idle":"2025-04-17T04:07:02.254263Z","shell.execute_reply.started":"2025-04-17T04:07:02.248943Z","shell.execute_reply":"2025-04-17T04:07:02.253645Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# 8. TRAINING LOOP\n- Loop over epochs, track train/val loss & acc  \n- Save best model weights when validation accuracy improves  \n","metadata":{}},{"cell_type":"code","source":"# 8. TRAINING LOOP\nmetrics = []\nbest_acc = 0.0\n\nfor epoch in range(1, EPOCHS + 1):\n    start = time.time()\n    train_loss, train_acc, _, _ = run_epoch(train_loader, train=True)\n    val_loss, val_acc, _, _     = run_epoch(val_loader, train=False)\n    metrics.append({\n        \"epoch\": epoch,\n        \"train_loss\": round(train_loss, 4),\n        \"val_loss\":   round(val_loss,   4),\n        \"val_acc\":    round(val_acc,    3)\n    })\n    print(\n        f\"Epoch {epoch:02d}/{EPOCHS}  \"\n        f\"train_loss {train_loss:.4f}  val_loss {val_loss:.4f}  \"\n        f\"val_acc {val_acc:.3f}  time {time.time()-start:.1f}s\",\n        file=sys.stderr\n    )\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), MODEL_WEIGHTS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:02.255022Z","iopub.execute_input":"2025-04-17T04:07:02.255778Z","iopub.status.idle":"2025-04-17T04:07:06.156443Z","shell.execute_reply.started":"2025-04-17T04:07:02.255720Z","shell.execute_reply":"2025-04-17T04:07:06.155484Z"}},"outputs":[{"name":"stderr","text":"Epoch 01/6  train_loss 0.9429  val_loss 0.6570  val_acc 0.848  time 0.7s\nEpoch 02/6  train_loss 0.5873  val_loss 0.4700  val_acc 0.848  time 0.6s\nEpoch 03/6  train_loss 0.5200  val_loss 0.4712  val_acc 0.848  time 0.6s\nEpoch 04/6  train_loss 0.5114  val_loss 0.4479  val_acc 0.848  time 0.6s\nEpoch 05/6  train_loss 0.4925  val_loss 0.4402  val_acc 0.891  time 0.6s\nEpoch 06/6  train_loss 0.4750  val_loss 0.4331  val_acc 0.891  time 0.6s\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# 9. EPOCH METRICS TABLE\nDisplay per‑epoch losses & validation accuracy as a pandas table.\n","metadata":{}},{"cell_type":"code","source":"# 9. EPOCH METRICS TABLE\nprint(\"\\nEpoch metrics\")\nprint(pd.DataFrame(metrics).to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:06.157493Z","iopub.execute_input":"2025-04-17T04:07:06.158030Z","iopub.status.idle":"2025-04-17T04:07:06.164610Z","shell.execute_reply.started":"2025-04-17T04:07:06.158003Z","shell.execute_reply":"2025-04-17T04:07:06.164036Z"}},"outputs":[{"name":"stdout","text":"\nEpoch metrics\n epoch  train_loss  val_loss  val_acc\n     1      0.9429    0.6570    0.848\n     2      0.5873    0.4700    0.848\n     3      0.5200    0.4712    0.848\n     4      0.5114    0.4479    0.848\n     5      0.4925    0.4402    0.891\n     6      0.4750    0.4331    0.891\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# 10. CLASSIFICATION REPORT\n- Load the best saved weights  \n- Run one final evaluation on validation set  \n- Print sklearn’s classification report + best val accuracy\n","metadata":{}},{"cell_type":"code","source":"# 10. CLASSIFICATION REPORT\n\ntry:\n    model.load_state_dict(torch.load(MODEL_WEIGHTS, weights_only=True))\nexcept TypeError:\n    model.load_state_dict(torch.load(MODEL_WEIGHTS))\n\n# get predictions\n_, _, y_pred, y_true = run_epoch(val_loader, train=False)\nprint(\"\\nClassification report\")\nprint(classification_report(\n    y_true, y_pred,\n    target_names=[train_ds.id2label[i] for i in range(N_CLASSES)],\n    zero_division=0\n))\nprint(f\"\\nBest validation accuracy: {best_acc:.3f}\")\nprint(f\"Model weights saved to {MODEL_WEIGHTS}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:06.165459Z","iopub.execute_input":"2025-04-17T04:07:06.165950Z","iopub.status.idle":"2025-04-17T04:07:06.282208Z","shell.execute_reply.started":"2025-04-17T04:07:06.165919Z","shell.execute_reply":"2025-04-17T04:07:06.281450Z"}},"outputs":[{"name":"stdout","text":"\nClassification report\n              precision    recall  f1-score   support\n\n     LABEL_0       0.89      1.00      0.94       140\n     LABEL_1       1.00      0.41      0.58        17\n     LABEL_2       0.00      0.00      0.00         8\n\n    accuracy                           0.89       165\n   macro avg       0.63      0.47      0.51       165\nweighted avg       0.85      0.89      0.86       165\n\n\nBest validation accuracy: 0.891\nModel weights saved to ./bilstm_sentiment.pt\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# 11. INFERENCE FUNCTIONS\n- `predict(text)` tokenizes & runs the model to return label + confidence  \n- `demo(lines)` prints a few example inferences  \n","metadata":{}},{"cell_type":"code","source":"# 11. INFERENCE FUNCTIONS\ndef predict(text):\n    ids = [VOCAB[t] for t in tokenize(text)[:MAX_LEN]] or [VOCAB[\"<unk>\"]]\n    tensor = torch.tensor(ids, device=DEVICE).unsqueeze(0)\n    length = torch.tensor([len(ids)], device=DEVICE)\n    with torch.no_grad():\n        logits = model(tensor, length)\n    idx  = logits.argmax(1).item()\n    conf = torch.softmax(logits, 1).max().item()\n    return train_ds.id2label[idx], conf\n\ndef demo(lines):\n    print(\"\\nInference examples\")\n    for s in lines:\n        label, conf = predict(s)\n        print(f\"'{s}' -> {label}  ({conf:.2%})\")\n\n# run demo\ndemo([\n    \"I absolutely loved this product!\",\n    \"This is the worst experience I've ever had.\",\n    \"\"\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:07:06.284076Z","iopub.execute_input":"2025-04-17T04:07:06.284607Z","iopub.status.idle":"2025-04-17T04:07:06.296332Z","shell.execute_reply.started":"2025-04-17T04:07:06.284582Z","shell.execute_reply":"2025-04-17T04:07:06.295620Z"}},"outputs":[{"name":"stdout","text":"\nInference examples\n'I absolutely loved this product!' -> LABEL_0  (82.02%)\n'This is the worst experience I've ever had.' -> LABEL_0  (91.46%)\n'' -> LABEL_1  (39.25%)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}